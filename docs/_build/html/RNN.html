

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>Recurrent Neural Network (RNN) &mdash; EpyNN 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="./" src="_static/documentation_options.js"></script>
        <script src="_static/jquery.js"></script>
        <script src="_static/underscore.js"></script>
        <script src="_static/doctools.js"></script>
        <script src="_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Many-to-one RNN" href="nnlive/dummy_string/RNN_binary.html" />
    <link rel="prev" title="Fully Connected (Dense)" href="Dense.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="index.html" class="icon icon-home"> EpyNN
          

          
            
            <img src="_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="epynn.html">EpyNN Objects</a></li>
<li class="toctree-l1"><a class="reference internal" href="Embedding.html">Data Embedding (Input)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Dense.html">Fully Connected (Dense)</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Recurrent Neural Network (RNN)</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#layer-architecture">Layer architecture</a></li>
<li class="toctree-l2"><a class="reference internal" href="#live-examples">Live examples</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#dummy-string-data">Dummy string data</a><ul>
<li class="toctree-l4"><a class="reference internal" href="nnlive/dummy_string/RNN_binary.html">Many-to-one RNN</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="LSTM.html">Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="GRU.html">Gated Recurrent Unit (GRU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Convolution.html">Convolutional Neural Network (CNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="Dropout.html">Dropout</a></li>
<li class="toctree-l1"><a class="reference internal" href="Flatten.html">Flatten</a></li>
<li class="toctree-l1"><a class="reference internal" href="examples.html">Examples and data</a></li>
<li class="toctree-l1"><a class="reference internal" href="Details.html">Details</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="index.html">EpyNN</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="index.html" class="icon icon-home"></a> &raquo;</li>
        
      <li>Recurrent Neural Network (RNN)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
          
            <a href="_sources/RNN.rst.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="recurrent-neural-network-rnn">
<h1>Recurrent Neural Network (RNN)<a class="headerlink" href="#recurrent-neural-network-rnn" title="Permalink to this headline">¶</a></h1>
<div class="section" id="layer-architecture">
<h2>Layer architecture<a class="headerlink" href="#layer-architecture" title="Permalink to this headline">¶</a></h2>
<img alt="_images/rnn1-01.svg" src="_images/rnn1-01.svg" /><dl class="py class">
<dt id="nnlibs.rnn.models.RNN">
<em class="property">class </em><code class="sig-prename descclassname">nnlibs.rnn.models.</code><code class="sig-name descname">RNN</code><span class="sig-paren">(</span><em class="sig-param">hidden_size=10</em>, <em class="sig-param">activate=&lt;function softmax&gt;</em>, <em class="sig-param">activate_hidden=&lt;function tanh&gt;</em>, <em class="sig-param">initialization=&lt;function xavier&gt;</em>, <em class="sig-param">binary=False</em><span class="sig-paren">)</span><a class="reference internal" href="_modules/nnlibs/rnn/models.html#RNN"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnlibs.rnn.models.RNN" title="Permalink to this definition">¶</a></dt>
<dd><p>Bases: <a class="reference internal" href="epynn.html#nnlibs.commons.models.Layer" title="nnlibs.commons.models.Layer"><code class="xref py py-class docutils literal notranslate"><span class="pre">nnlibs.commons.models.Layer</span></code></a></p>
<p>Definition of a RNN layer prototype.</p>
<dl class="field-list simple">
<dt class="field-odd">Parameters</dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_size</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#int" title="(in Python v3.9)"><em>int</em></a>) – Number of RNN cells in one RNN layer.</p></li>
<li><p><strong>activate</strong> (<em>function</em>) – Activation function for output of RNN cells.</p></li>
<li><p><strong>activate_hidden</strong> (<em>function</em>) – Activation function for hidden state of RNN cells.</p></li>
<li><p><strong>initialization</strong> (<em>function</em>) – Weight initialization function for RNN layer.</p></li>
<li><p><strong>binary</strong> (<a class="reference external" href="https://docs.python.org/3/library/functions.html#bool" title="(in Python v3.9)"><em>bool</em></a>) – Set the RNN layer from many-to-many to many-to-one mode.</p></li>
</ul>
</dd>
</dl>
<dl class="py method">
<dt id="nnlibs.rnn.models.RNN.compute_shapes">
<code class="sig-name descname">compute_shapes</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/nnlibs/rnn/models.html#RNN.compute_shapes"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnlibs.rnn.models.RNN.compute_shapes" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for <a class="reference internal" href="Details.html#nnlibs.rnn.parameters.rnn_compute_shapes" title="nnlibs.rnn.parameters.rnn_compute_shapes"><code class="xref py py-func docutils literal notranslate"><span class="pre">nnlibs.rnn.parameters.rnn_compute_shapes()</span></code></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rnn_compute_shapes</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute forward shapes and dimensions for cells and layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">A</span>    <span class="c1"># Input of current layer of shape (s, v, m)</span>

    <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;s&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>    <span class="c1"># Length of sequence (s)</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>    <span class="c1"># Vocabulary size (v)</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">2</span><span class="p">]</span>    <span class="c1"># Number of samples (m)</span>
    <span class="c1"># Max length (l) between cells and sequence</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;l&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;s&#39;</span><span class="p">])</span>
    <span class="c1"># Output length (o)</span>
    <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="mi">2</span> <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">binary</span> <span class="k">else</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">]</span>

    <span class="c1"># Shapes for parameters to compute hidden cell state to next cell</span>
    <span class="n">hv</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;Wx&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">])</span>
    <span class="n">hh</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;Wh&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">])</span>
    <span class="n">h1</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;bh&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>
    <span class="c1"># Shapes for parameters to compute cell output to next layer</span>
    <span class="n">oh</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">])</span>
    <span class="n">o1</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span>

    <span class="c1"># Shapes to initialize caches</span>
    <span class="n">lvm</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;l&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;v&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">])</span>
    <span class="n">hhm</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">])</span>
    <span class="n">ohm</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fs</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;o&#39;</span><span class="p">],</span> <span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;m&#39;</span><span class="p">])</span>

    <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
</dd></dl>

<dl class="py method">
<dt id="nnlibs.rnn.models.RNN.forward">
<code class="sig-name descname">forward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">A</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/nnlibs/rnn/models.html#RNN.forward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnlibs.rnn.models.RNN.forward" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for <a class="reference internal" href="Details.html#nnlibs.rnn.forward.rnn_forward" title="nnlibs.rnn.forward.rnn_forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">nnlibs.rnn.forward.rnn_forward()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rnn_forward</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">A</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Forward propagate signal through RNN cells to next layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># (1) Initialize cache and cell state</span>
    <span class="n">X</span><span class="p">,</span> <span class="n">hp</span> <span class="o">=</span> <span class="n">initialize_forward</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>

    <span class="c1"># Iterate through sequence to next cell</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">]):</span>

        <span class="c1"># (2s) Slice sequence (l, v, m) with respect to step</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>

        <span class="c1"># (3s) Compute cell state</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;Wx&#39;</span><span class="p">],</span> <span class="n">X</span><span class="p">)</span>
        <span class="n">h</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;Wh&#39;</span><span class="p">],</span> <span class="n">hp</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;bh&#39;</span><span class="p">]</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">hp</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">activate_hidden</span><span class="p">(</span><span class="n">h</span><span class="p">)</span>

        <span class="c1"># (4s) Compute cell output to next layer</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">],</span> <span class="n">h</span><span class="p">)</span> <span class="o">+</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;b&#39;</span><span class="p">]</span>
        <span class="n">A</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;A&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">activate</span><span class="p">(</span><span class="n">A</span><span class="p">)</span>

    <span class="c1"># Return layer.fc[&#39;A&#39;] if many-to-many mode</span>
    <span class="n">A</span> <span class="o">=</span> <span class="n">terminate_forward</span><span class="p">(</span><span class="n">layer</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">A</span>    <span class="c1"># To next layer</span>
</pre></div>
</div>
<img alt="_images/rnn2-01.svg" src="_images/rnn2-01.svg" /><div class="math notranslate nohighlight">
\[X = A \tag{1}\]</div>
<div class="math notranslate nohighlight">
\[X_s = X[:, s] \tag{2s}\]</div>
<div class="math notranslate nohighlight">
\[h_s = h_{act}(W_x \cdot X_s + W_h \cdot h_{s-1} + b_h) \tag{3s}\]</div>
<div class="math notranslate nohighlight">
\[A_s = A_{act}(W \cdot h_s + b) \tag{4s}\]</div>
</dd></dl>

<dl class="py method">
<dt id="nnlibs.rnn.models.RNN.backward">
<code class="sig-name descname">backward</code><span class="sig-paren">(</span><em class="sig-param"><span class="n">dA</span></em><span class="sig-paren">)</span><a class="reference internal" href="_modules/nnlibs/rnn/models.html#RNN.backward"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnlibs.rnn.models.RNN.backward" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for <a class="reference internal" href="Details.html#nnlibs.rnn.backward.rnn_backward" title="nnlibs.rnn.backward.rnn_backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">nnlibs.rnn.backward.rnn_backward()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rnn_backward</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">dA</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Backward propagate signal through RNN cells to previous layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># (1) Initialize cache and cell state</span>
    <span class="n">dX</span><span class="p">,</span> <span class="n">dhn</span> <span class="o">=</span> <span class="n">initialize_backward</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">dA</span><span class="p">)</span>

    <span class="c1"># Iterate through reversed sequence to previous cell</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">])):</span>

        <span class="c1"># (2s) Slice sequence (l, v, m) with respect to step</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">dX</span> <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">binary</span> <span class="k">else</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dX&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>

        <span class="c1"># (3s) Compute partial derivative of cell state error</span>
        <span class="n">dh</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">dhn</span><span class="p">)</span> <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">binary</span> <span class="k">else</span> <span class="n">dhn</span>
        <span class="n">dh</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;W&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dX</span><span class="p">)</span>
        <span class="n">dh</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dh&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">dh</span> <span class="o">*</span> <span class="n">layer</span><span class="o">.</span><span class="n">activate_hidden</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">],</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1"># (4s) With respect to cell state</span>
        <span class="n">dhn</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dhn&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;Wh&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dh</span><span class="p">)</span>

        <span class="c1"># (5s) With respect to cell input</span>
        <span class="n">dA</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dA&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="s1">&#39;Wx&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">dh</span><span class="p">)</span>

    <span class="n">dA</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dA&#39;</span><span class="p">]</span>

    <span class="k">return</span> <span class="n">dA</span>    <span class="c1"># To previous layer</span>
</pre></div>
</div>
<img alt="_images/rnn3-01.svg" src="_images/rnn3-01.svg" /><div class="math notranslate nohighlight">
\[dX = dA \tag{1}\]</div>
<div class="math notranslate nohighlight">
\[dX_s = dX[s] \tag{2s}\]</div>
<div class="math notranslate nohighlight">
\[dh_s = h_{act}'(h_s) \times (W.T \cdot dX_s + dh_{s+1}) \tag{3s}\]</div>
<div class="math notranslate nohighlight">
\[dh_{s+1} = W_h.T \cdot dh_s \tag{4s}\]</div>
<div class="math notranslate nohighlight">
\[dA_{s} = W_x.T \cdot dh_s \tag{5s}\]</div>
</dd></dl>

<dl class="py method">
<dt id="nnlibs.rnn.models.RNN.compute_gradients">
<code class="sig-name descname">compute_gradients</code><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="_modules/nnlibs/rnn/models.html#RNN.compute_gradients"><span class="viewcode-link">[source]</span></a><a class="headerlink" href="#nnlibs.rnn.models.RNN.compute_gradients" title="Permalink to this definition">¶</a></dt>
<dd><p>Wrapper for <a class="reference internal" href="Details.html#nnlibs.rnn.parameters.rnn_compute_gradients" title="nnlibs.rnn.parameters.rnn_compute_gradients"><code class="xref py py-func docutils literal notranslate"><span class="pre">nnlibs.rnn.parameters.rnn_compute_gradients()</span></code></a>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">rnn_compute_gradients</span><span class="p">(</span><span class="n">layer</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute gradients with respect to weight and bias for cells and layer.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># Gradients initialization with respect to parameters</span>
    <span class="k">for</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
        <span class="n">gradient</span> <span class="o">=</span> <span class="s1">&#39;d&#39;</span> <span class="o">+</span> <span class="n">parameter</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="n">gradient</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">p</span><span class="p">[</span><span class="n">parameter</span><span class="p">])</span>

    <span class="c1"># Iterate through reversed sequence</span>
    <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">layer</span><span class="o">.</span><span class="n">d</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">])):</span>

        <span class="c1">#</span>
        <span class="n">h</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>   <span class="c1"># Current cell state</span>
        <span class="n">dX</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dX&#39;</span><span class="p">]</span> <span class="k">if</span> <span class="n">layer</span><span class="o">.</span><span class="n">binary</span> <span class="k">else</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dX&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>
        <span class="c1"># Gradients</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;dW&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dX</span><span class="p">,</span> <span class="n">h</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;db&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dX</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="c1">#</span>
        <span class="n">dh</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">bc</span><span class="p">[</span><span class="s1">&#39;dh&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>     <span class="c1"># Current cell state error</span>
        <span class="n">hp</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;h&#39;</span><span class="p">][</span><span class="n">s</span> <span class="o">-</span> <span class="mi">1</span><span class="p">]</span>  <span class="c1"># Previous cell state</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">layer</span><span class="o">.</span><span class="n">fc</span><span class="p">[</span><span class="s1">&#39;X&#39;</span><span class="p">][</span><span class="n">s</span><span class="p">]</span>       <span class="c1"># Current cell input</span>
        <span class="c1"># Gradients</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;dWx&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dh</span><span class="p">,</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;dWh&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">dh</span><span class="p">,</span> <span class="n">hp</span><span class="o">.</span><span class="n">T</span><span class="p">)</span>
        <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="s1">&#39;dbh&#39;</span><span class="p">]</span> <span class="o">+=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dh</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="k">return</span> <span class="kc">None</span>
</pre></div>
</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
  dW_s &amp;= dX_s \cdot h_s  \\
  db_s &amp;= \sum_{j = 1}^n dX_{s_{ij}}  \tag{A}
\end{align}\end{split}\]</div>
<div class="math notranslate nohighlight">
\[\begin{split}\begin{align}
  dW_{x_s} &amp;= dh_s \cdot X_s  \\
  dW_{h_s} &amp;= dh_s \cdot h_{s-1} \\
  db_{h_s} &amp;= \sum_{j = 1}^n dh_{s_{ij}} \tag{B}
\end{align}\end{split}\]</div>
</dd></dl>

</dd></dl>

</div>
<div class="section" id="live-examples">
<h2>Live examples<a class="headerlink" href="#live-examples" title="Permalink to this headline">¶</a></h2>
<div class="section" id="dummy-string-data">
<h3>Dummy string data<a class="headerlink" href="#dummy-string-data" title="Permalink to this headline">¶</a></h3>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="nnlive/dummy_string/RNN_binary.html">Many-to-one RNN</a></li>
</ul>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
        <a href="nnlive/dummy_string/RNN_binary.html" class="btn btn-neutral float-right" title="Many-to-one RNN" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
        <a href="Dense.html" class="btn btn-neutral float-left" title="Fully Connected (Dense)" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Florian Malard and Stéphanie Olivier-Van Stichelen.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>