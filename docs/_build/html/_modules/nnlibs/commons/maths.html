

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  
  <title>nnlibs.commons.maths &mdash; EpyNN 0.1.0 documentation</title>
  

  
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/pygments.css" type="text/css" />

  
  

  
  

  

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../../" src="../../../_static/documentation_options.js"></script>
        <script src="../../../_static/jquery.js"></script>
        <script src="../../../_static/underscore.js"></script>
        <script src="../../../_static/doctools.js"></script>
        <script src="../../../_static/language_data.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script async="async" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "tex2jax_process|mathjax_process|math|output_area"}})</script>
    
    <script type="text/javascript" src="../../../_static/js/theme.js"></script>

    
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../../index.html" class="icon icon-home"> EpyNN
          

          
            
            <img src="../../../_static/logo.png" class="logo" alt="Logo"/>
          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        
        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../quickstart.html">Quick Start</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Introduction.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../EpyNN_Model.html">Neural Network (Model)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Layer_Model.html">Architecture Layers (Model)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Embedding.html">Data Embedding (Input)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Dense.html">Fully Connected (Dense)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../RNN.html">Recurrent Neural Network (RNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../LSTM.html">Long Short-Term Memory (LSTM)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../GRU.html">Gated Recurrent Unit (GRU)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Convolution.html">Convolutional Neural Network (CNN)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Dropout.html">Dropout</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Flatten.html">Flatten</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../examples.html">Examples and data</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../Details.html">Details</a></li>
</ul>

            
          
        </div>
        
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">EpyNN</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          

















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../../index.html" class="icon icon-home"></a> &raquo;</li>
        
          <li><a href="../../index.html">Module code</a> &raquo;</li>
        
      <li>nnlibs.commons.maths</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <h1>Source code for nnlibs.commons.maths</h1><div class="highlight"><pre>
<span></span><span class="c1"># EpyNN/nnlibs/commons/maths.py</span>
<span class="c1"># Standard library imports</span>
<span class="kn">import</span> <span class="nn">random</span>

<span class="c1"># Related third party imports</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>


<span class="n">E_SAFE</span> <span class="o">=</span> <span class="mf">1e-10</span>


<div class="viewcode-block" id="activation_tune"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.activation_tune">[docs]</a><span class="k">def</span> <span class="nf">activation_tune</span><span class="p">(</span><span class="n">se_hPars</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">global</span> <span class="n">layer_hPars</span>
    <span class="n">layer_hPars</span> <span class="o">=</span> <span class="n">se_hPars</span></div>


<span class="c1">### Activation functions and derivatives</span>

<span class="c1"># Identity function</span>

<div class="viewcode-block" id="identity"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.identity">[docs]</a><span class="k">def</span> <span class="nf">identity</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute ReLU activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Rectifier Linear Unit (ReLU)</span>

<div class="viewcode-block" id="relu"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.relu">[docs]</a><span class="k">def</span> <span class="nf">relu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute ReLU activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">greater</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="nb">int</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Leaky Rectifier Linear Unit (LReLU)</span>

<div class="viewcode-block" id="lrelu"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.lrelu">[docs]</a><span class="k">def</span> <span class="nf">lrelu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute LReLU activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">layer_hPars</span><span class="p">[</span><span class="s1">&#39;LRELU_alpha&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">maximum</span><span class="p">(</span><span class="n">a</span> <span class="o">*</span> <span class="n">x</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Exponential Linear Unit (ELU)</span>

<div class="viewcode-block" id="elu"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.elu">[docs]</a><span class="k">def</span> <span class="nf">elu</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute ELU activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">a</span> <span class="o">=</span> <span class="n">layer_hPars</span><span class="p">[</span><span class="s1">&#39;ELU_alpha&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">a</span> <span class="o">*</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">x</span><span class="o">&lt;=</span><span class="mi">0</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">x</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">elu</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">a</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Sigmoid (σ)</span>

<div class="viewcode-block" id="sigmoid"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.sigmoid">[docs]</a><span class="k">def</span> <span class="nf">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Sigmoid activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span>
                    <span class="n">x</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">,</span> <span class="c1"># condition</span>
                    <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)),</span> <span class="c1"># For positive values</span>
                    <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span> <span class="c1"># For negative values</span>
                    <span class="p">)</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Swish</span>

<div class="viewcode-block" id="swish"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.swish">[docs]</a><span class="k">def</span> <span class="nf">swish</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute Swish activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">sigmoid</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="k">pass</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Hyperbolic tangent (tanh)</span>

<div class="viewcode-block" id="tanh"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.tanh">[docs]</a><span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute tanh activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">-</span> <span class="mi">1</span><span class="p">)</span> <span class="o">/</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">x</span><span class="o">**</span><span class="mi">2</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1"># Softmax</span>

<div class="viewcode-block" id="softmax"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.softmax">[docs]</a><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">deriv</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Compute softmax activation or derivative</span>

<span class="sd">    :param x: Input array to pass in function</span>
<span class="sd">    :type x: class:`numpy.ndarray`</span>

<span class="sd">    :param deriv: To compute derivative</span>
<span class="sd">    :type deriv: bool</span>

<span class="sd">    :return: Output array passed in function</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">T</span> <span class="o">=</span> <span class="n">layer_hPars</span><span class="p">[</span><span class="s1">&#39;softmax_temperature&#39;</span><span class="p">]</span>

    <span class="k">if</span> <span class="ow">not</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x_safe</span> <span class="o">=</span> <span class="n">x</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">x_exp</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="n">x_safe</span> <span class="o">/</span> <span class="n">T</span><span class="p">)</span>
        <span class="n">x_sum</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">x_exp</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdims</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

        <span class="n">x</span> <span class="o">=</span> <span class="n">x_exp</span> <span class="o">/</span> <span class="n">x_sum</span>

    <span class="k">elif</span> <span class="n">deriv</span><span class="p">:</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">x</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">x</span></div>


<span class="c1">### Weight initialization</span>

<div class="viewcode-block" id="xavier"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.xavier">[docs]</a><span class="k">def</span> <span class="nf">xavier</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Xavier initialization for weight array.</span>

<span class="sd">    :param shape: Shape of weight array</span>
<span class="sd">    :type shape: tuple</span>

<span class="sd">    :param rng: Pseudo-random number generator</span>
<span class="sd">    :type rng: :class:`numpy.random`</span>

<span class="sd">    :return: Initialized weight array</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">W</span> <span class="o">/=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">return</span> <span class="n">W</span></div>


<div class="viewcode-block" id="orthogonal"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.orthogonal">[docs]</a><span class="k">def</span> <span class="nf">orthogonal</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">rng</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Orthogonal initialization for weight array.</span>

<span class="sd">    :param shape: Shape of weight array</span>
<span class="sd">    :type shape: tuple</span>

<span class="sd">    :param rng: Pseudo-random number generator</span>
<span class="sd">    :type rng: :class:`numpy.random`</span>

<span class="sd">    :return: Initialized weight array</span>
<span class="sd">    :rtype: class:`numpy.ndarray`</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">W</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">standard_normal</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">W</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">else</span> <span class="n">W</span>

    <span class="c1"># Compute QR factorization</span>
    <span class="n">q</span><span class="p">,</span> <span class="n">r</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">qr</span><span class="p">(</span><span class="n">W</span><span class="p">)</span>

    <span class="c1"># Make Q uniform according to https://arxiv.org/pdf/math-ph/0609050.pdf</span>
    <span class="n">d</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
    <span class="n">ph</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sign</span><span class="p">(</span><span class="n">d</span><span class="p">)</span>
    <span class="n">q</span> <span class="o">*=</span> <span class="n">ph</span>

    <span class="n">W</span> <span class="o">=</span> <span class="n">q</span><span class="o">.</span><span class="n">T</span> <span class="k">if</span> <span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">&lt;</span> <span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="k">else</span> <span class="n">q</span>

    <span class="k">return</span> <span class="n">W</span></div>


<div class="viewcode-block" id="clip_gradient"><a class="viewcode-back" href="../../../Details.html#nnlibs.commons.maths.clip_gradient">[docs]</a><span class="k">def</span> <span class="nf">clip_gradient</span><span class="p">(</span><span class="n">layer</span><span class="p">,</span> <span class="n">max_norm</span><span class="o">=</span><span class="mf">0.25</span><span class="p">):</span>
    <span class="sd">&quot;&quot;&quot;Clip to avoid vanishing or exploding gradients</span>

<span class="sd">    :param layer: An instance of active layer</span>
<span class="sd">    :type layer:</span>

<span class="sd">    :param max_norm:</span>
<span class="sd">    :type max_norm: float</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">total_norm</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Calculate the L2 norm squared for each gradient and add them to the total norm</span>
    <span class="k">for</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="n">values</span><span class="p">():</span>
        <span class="n">grad_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">power</span><span class="p">(</span><span class="n">grad</span> <span class="o">+</span> <span class="n">E_SAFE</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>
        <span class="n">total_norm</span> <span class="o">+=</span> <span class="n">grad_norm</span>

    <span class="n">total_norm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">total_norm</span><span class="p">)</span>

    <span class="c1"># Calculate clipping coeficient</span>
    <span class="n">clip_coef</span> <span class="o">=</span> <span class="n">max_norm</span> <span class="o">/</span> <span class="p">(</span><span class="n">total_norm</span><span class="o">+</span><span class="mf">1e-6</span><span class="p">)</span>

    <span class="c1"># If the total norm is larger than the maximum allowable norm, then clip the gradient</span>
    <span class="k">if</span> <span class="n">clip_coef</span> <span class="o">&lt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="o">.</span><span class="n">keys</span><span class="p">():</span>
            <span class="n">layer</span><span class="o">.</span><span class="n">g</span><span class="p">[</span><span class="n">g</span><span class="p">]</span> <span class="o">*=</span> <span class="n">clip_coef</span>

    <span class="k">return</span> <span class="kc">None</span></div>
</pre></div>

           </div>
           
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>
        &#169; Copyright 2021, Florian Malard and Stéphanie Olivier-Van Stichelen.

    </p>
  </div>
    
    
    
    Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    
    provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>
        </div>
      </div>

    </section>

  </div>
  

  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>