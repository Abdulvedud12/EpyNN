{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distinguish author-specific patterns in music"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Find this notebook at `EpyNN/nnlive/author_music/train.ipynb`.\n",
    "* Regular python code at `EpyNN/nnlive/author_music/train.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we will review:\n",
    "\n",
    "* Handling univariate time series that represents a **huge amount of data points**.\n",
    "* Take advantage of recurrent architectures (RNN, GRU) over Feed-Forward architectures.\n",
    "* Introduce recall and precision along with accuracy when dealing with unbalanced datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment and data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Follow [this link](prepare_dataset.ipynb) for details about data preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Briefly, raw data are acoustic guittare music from the *True* author and the *False* author. These are raw ``.wav`` files that were resampled, clipped and digitalized using a 4-bits encoder.\n",
    "\n",
    "Commonly, music ``.wav`` files have a sampling rate of 44100 Hz. This means that each second of music represents a numerical time series of length 44100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EpyNN/nnlive/author_music/train.ipynb\n",
    "# Standard library imports\n",
    "import random\n",
    "\n",
    "# Related third party imports\n",
    "import numpy as np\n",
    "\n",
    "# Local application/library specific imports\n",
    "import nnlibs.initialize\n",
    "from nnlibs.commons.maths import relu, softmax\n",
    "from nnlibs.commons.library import (\n",
    "    configure_directory,\n",
    "    read_model,\n",
    ")\n",
    "from nnlibs.network.models import EpyNN\n",
    "from nnlibs.embedding.models import Embedding\n",
    "from nnlibs.rnn.models import RNN\n",
    "# from nnlibs.lstm.models import LSTM\n",
    "from nnlibs.gru.models import GRU\n",
    "from nnlibs.flatten.models import Flatten\n",
    "from nnlibs.dropout.models import Dropout\n",
    "from nnlibs.dense.models import Dense\n",
    "from prepare_dataset import prepare_dataset\n",
    "from settings import se_hPars\n",
    "\n",
    "\n",
    "########################## CONFIGURE ##########################\n",
    "random.seed(1)\n",
    "\n",
    "np.set_printoptions(threshold=10)\n",
    "\n",
    "np.seterr(all='warn')\n",
    "np.seterr(under='ignore')\n",
    "\n",
    "\n",
    "############################ DATASET ##########################\n",
    "X_features, Y_label = prepare_dataset(N_SAMPLES=1280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1280\n",
      "(10000,)\n",
      "[15 10 10 ... 13 13 13]\n",
      "0 15\n"
     ]
    }
   ],
   "source": [
    "print(len(X_features))\n",
    "print(X_features[0].shape)\n",
    "print(X_features[0])\n",
    "print(np.min(X_features[0]), np.max(X_features[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We clipped the original ``.wav`` files in 1 second clips and thus we could retrieve ``1280`` samples. We did that because we do not have an infinite number of data. Since we want more training examples, we need to split the data.\n",
    "\n",
    "Below other problems are discussed:\n",
    "\n",
    "* **Arrays size in memory**: One second represents 44100 data points for each clip and thus ``44100 * 1280 = 56.448e6`` data points in total. More than fifty millions of these is likely to overload your RAM or to raise a memory allocation error on most laptops. This is why we resampled the original ``.wav`` files content to 10000 Hz. When doing that, we loose the patterns associated with frequencies greater than 5000 Hz. Instead, we could have made clips of shorther duration but then we would miss patterns associated with lower frequencies. Because guittare emission spectrum is essentially filled below 5000 Hz, we prefered to apply the resampling method.\n",
    "* **Signal normalization**: Original signals were sequences of 16-bits integers ranging from ``0`` to ``32767``. Feeding a neural network which such big values will most likely result in floatting point errors. This is why we normalized the original data from each ``.wav`` file within the range \\[0, 1\\].\n",
    "* **Signal digitalization**: While the original signal was a digital signal encoded onver 16-bits integers, this results in ``3e-5`` difference between each digit after normalization within the range \\[0, 1\\]. Such thin differences may be difficult to be evaluated for the network and the training could turn prohibitively slow. In the context of this notebook, we digitalized again but using 4-bits integers ranging from ``0`` to ``15`` for then a total of 16 values instead of 32768.  \n",
    "\n",
    "All things being said, we can go ahead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward (FF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first start by our reference, a Feed-Forward network with dropout regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scaled input data for each ``.wav`` file before, so we do not need to provide the argument to the class constructor of the *embedding* layer. Note that when ``X_scale=True`` it applies a global scaling over the whole training set. Here we work with independant ``.wav`` files which should be normalized separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(X_data=X_features,\n",
    "                      Y_data=Y_label,\n",
    "                      Y_encode=True,\n",
    "                      batch_size=16,\n",
    "                      relative_size=(2, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the shape of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853, 10000)\n",
      "{1: 378, 0: 475}\n"
     ]
    }
   ],
   "source": [
    "print(embedding.dtrain.X.shape)\n",
    "print(embedding.dtrain.b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We note that we have an unbalanced dataset, with about 2/3 of negative samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten-(Dense)n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's proceed with the network design and training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'Flatten_Dense-64-relu_Dense-2-softmax'\n",
    "\n",
    "# se_hPars['learning_rate'] = 0.00001\n",
    "# se_hPars['learning_rate'] = 1\n",
    "se_hPars['learning_rate'] = 0.01\n",
    "se_hPars['softmax_temperature'] = 1\n",
    "\n",
    "layers = [\n",
    "    embedding,\n",
    "    Dense(64, relu),\n",
    "    Dense(2, softmax),\n",
    "]\n",
    "\n",
    "model = EpyNN(layers=layers, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We have set the softmax temperature to ``5`` to diminish the confidence of the model and the risk of vanishing/exploding gradients.\n",
    "\n",
    "We can initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--- EpyNN Check OK! --- \u001b[0mdding\u001b[0m\u001b[0m\r"
     ]
    }
   ],
   "source": [
    "model.initialize(loss='MSE', seed=1, metrics=['accuracy', 'recall', 'precision'], se_hPars=se_hPars.copy(), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train it for 50 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+--------------------------------------------------+\n",
      "| \u001b[1m\u001b[37mepoch\u001b[0m |  \u001b[1m\u001b[37mlrate\u001b[0m   |  \u001b[1m\u001b[37mlrate\u001b[0m   |       | \u001b[1m\u001b[32maccuracy\u001b[0m |       | \u001b[1m\u001b[31mrecall\u001b[0m |       | \u001b[1m\u001b[35mprecision\u001b[0m |       |  \u001b[1m\u001b[36mMSE\u001b[0m  |                    \u001b[37mExperiment\u001b[0m                    |\n",
      "|       |  \u001b[37mDense\u001b[0m   |  \u001b[37mDense\u001b[0m   |  \u001b[1m\u001b[32m(0)\u001b[0m  |   \u001b[1m\u001b[32m(1)\u001b[0m    |  \u001b[1m\u001b[31m(0)\u001b[0m  |  \u001b[1m\u001b[31m(1)\u001b[0m   |  \u001b[1m\u001b[35m(0)\u001b[0m  |    \u001b[1m\u001b[35m(1)\u001b[0m    |  \u001b[1m\u001b[36m(0)\u001b[0m  |  \u001b[1m\u001b[36m(1)\u001b[0m  |                                                  |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+--------------------------------------------------+\n",
      "|   \u001b[1m\u001b[37m0\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m1\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m2\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m3\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m4\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m5\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m6\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m7\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m8\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m9\u001b[0m   | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[37m1.00e-02\u001b[0m | \u001b[1m\u001b[32m0.557\u001b[0m |  \u001b[1m\u001b[32m0.522\u001b[0m   | \u001b[1m\u001b[31m1.000\u001b[0m | \u001b[1m\u001b[31m1.000\u001b[0m  | \u001b[1m\u001b[35m0.557\u001b[0m |   \u001b[1m\u001b[35m0.522\u001b[0m   | \u001b[1m\u001b[36m0.443\u001b[0m | \u001b[1m\u001b[36m0.478\u001b[0m | \u001b[37m1628930905_Flatten_Dense-64-relu_Dense-2-softmax\u001b[0m |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+--------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=10, init_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At least we have no overfitting, because we have no fit at all. There are 10 000 features per sample, the problem seems too complex. We will pass and use a more appropriate architecture with respect to the situation.\n",
    "\n",
    "We can still comment the **recall** and **precision** metrics:\n",
    "\n",
    "* **Recall**: It represents *the fraction of positive instances retrieved by the model*.\n",
    "* **Precision**: It represents *the fraction of positive instances within the labels predicted as positive*. \n",
    "\n",
    "Said differently:\n",
    "\n",
    "* Given **tp** the *true positive* samples.\n",
    "* Given **tn** the *true negative* samples.\n",
    "* Given **fp** the *false positive* samples.\n",
    "* Given **fn** the *false negative* samples.\n",
    "* Then **recall** = ``tp / (tp+fn)`` and **precision** = ``tp / (tp+fp)``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Architectures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent architectures can make a difference here because they process time series one measurement by one measurement. \n",
    "\n",
    "The number of time steps **does not define the size of parameters (weight/bias) array** while in the Feed-Forward network this is the case. \n",
    "\n",
    "For the *dense*, the shape of W is ``p, n`` given ``p`` the number of nodes in the previous layer and ``n`` in the current layer. So when a *dense* layer follows the *embedding* layer, the number of nodes in the *embedding* layer is equal to the number of features, herein the number of time steps ``10 000``. \n",
    "\n",
    "By contrast, the *RNN* layer has parameters shape which depends on the number of cells and the uni/multivariate nature of each measurement, but not depending of the number of time steps. In the previous situation there is likely too much parameters and the computation does not converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the embedding, we will one-hot encode time series and we know the *\"vocabulary\"* size will be 16 because we digitalized over 16 bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = Embedding(X_data=X_features,\n",
    "                      Y_data=Y_label,\n",
    "                      X_encode=True,\n",
    "                      Y_encode=True,\n",
    "                      batch_size=128,\n",
    "                      relative_size=(2, 1, 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the data shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(853, 10000, 16)\n"
     ]
    }
   ],
   "source": [
    "print(embedding.dtrain.X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN(sequences=True)-Flatten-Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Time to clarify a point:\n",
    "\n",
    "* We have multivariate like time series (one-hot encoding) with 10000 time steps.\n",
    "* The 10000 or **length of sequence is unrelated to the number of cells in the RNN layer**. The number of cells may be whatever, the whole sequence will entirely be processed.\n",
    "* In recurrent layers, parameters shape is related to the number of cells and the vocabulary size, not to the length of the sequence. That's why such architectures can handle input sequences of variable lenth.\n",
    "\n",
    "Therefore, we can use only 2 cells on a sequence with 10 000 steps. With setting ``sequences=True`` this will return an array of shape ``(n_samples, 10000, 2)``. Without the flag, the shape will be ``n_samples, 1, 2)``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "name = 'RNN-2-Seq_Flatten_Dense-2-softmax'\n",
    "\n",
    "se_hPars['learning_rate'] = 0.1\n",
    "se_hPars['softmax_temperature'] = 1\n",
    "se_hPars['schedule'] = 'exp_decay'\n",
    "\n",
    "rnn = RNN(2, sequences=True)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "dense = Dense(2, softmax)\n",
    "\n",
    "layers = [embedding, rnn, flatten, dense]\n",
    "\n",
    "model = EpyNN(layers=layers, name=name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "We initialize the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m--- EpyNN Check OK! --- \u001b[0mdding\u001b[0m0m0m\r"
     ]
    }
   ],
   "source": [
    "model.initialize(loss='MSE', seed=1, metrics=['accuracy', 'recall', 'precision'], se_hPars=se_hPars.copy(), end='\\r')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only train for 5 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n",
      "| \u001b[1m\u001b[37mepoch\u001b[0m |  \u001b[1m\u001b[37mlrate\u001b[0m   |  \u001b[1m\u001b[37mlrate\u001b[0m   |       | \u001b[1m\u001b[32maccuracy\u001b[0m |       | \u001b[1m\u001b[31mrecall\u001b[0m |       | \u001b[1m\u001b[35mprecision\u001b[0m |       |  \u001b[1m\u001b[36mMSE\u001b[0m  |                  \u001b[37mExperiment\u001b[0m                  |\n",
      "|       |   \u001b[37mRNN\u001b[0m    |  \u001b[37mDense\u001b[0m   |  \u001b[1m\u001b[32m(0)\u001b[0m  |   \u001b[1m\u001b[32m(1)\u001b[0m    |  \u001b[1m\u001b[31m(0)\u001b[0m  |  \u001b[1m\u001b[31m(1)\u001b[0m   |  \u001b[1m\u001b[35m(0)\u001b[0m  |    \u001b[1m\u001b[35m(1)\u001b[0m    |  \u001b[1m\u001b[36m(0)\u001b[0m  |  \u001b[1m\u001b[36m(1)\u001b[0m  |                                              |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n",
      "|   \u001b[1m\u001b[37m0\u001b[0m   | \u001b[1m\u001b[37m1.00e-01\u001b[0m | \u001b[1m\u001b[37m1.00e-01\u001b[0m | \u001b[1m\u001b[32m0.735\u001b[0m |  \u001b[1m\u001b[32m0.756\u001b[0m   | \u001b[1m\u001b[31m0.644\u001b[0m | \u001b[1m\u001b[31m0.664\u001b[0m  | \u001b[1m\u001b[35m0.843\u001b[0m |   \u001b[1m\u001b[35m0.836\u001b[0m   | \u001b[1m\u001b[36m0.263\u001b[0m | \u001b[1m\u001b[36m0.242\u001b[0m | \u001b[37m1628930940_RNN-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m1\u001b[0m   | \u001b[1m\u001b[37m3.68e-02\u001b[0m | \u001b[1m\u001b[37m3.68e-02\u001b[0m | \u001b[1m\u001b[32m0.736\u001b[0m |  \u001b[1m\u001b[32m0.754\u001b[0m   | \u001b[1m\u001b[31m0.640\u001b[0m | \u001b[1m\u001b[31m0.655\u001b[0m  | \u001b[1m\u001b[35m0.849\u001b[0m |   \u001b[1m\u001b[35m0.839\u001b[0m   | \u001b[1m\u001b[36m0.261\u001b[0m | \u001b[1m\u001b[36m0.244\u001b[0m | \u001b[37m1628930940_RNN-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m2\u001b[0m   | \u001b[1m\u001b[37m1.35e-02\u001b[0m | \u001b[1m\u001b[37m1.35e-02\u001b[0m | \u001b[1m\u001b[32m0.758\u001b[0m |  \u001b[1m\u001b[32m0.754\u001b[0m   | \u001b[1m\u001b[31m0.672\u001b[0m | \u001b[1m\u001b[31m0.664\u001b[0m  | \u001b[1m\u001b[35m0.864\u001b[0m |   \u001b[1m\u001b[35m0.831\u001b[0m   | \u001b[1m\u001b[36m0.240\u001b[0m | \u001b[1m\u001b[36m0.242\u001b[0m | \u001b[37m1628930940_RNN-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m3\u001b[0m   | \u001b[1m\u001b[37m4.98e-03\u001b[0m | \u001b[1m\u001b[37m4.98e-03\u001b[0m | \u001b[1m\u001b[32m0.768\u001b[0m |  \u001b[1m\u001b[32m0.749\u001b[0m   | \u001b[1m\u001b[31m0.693\u001b[0m | \u001b[1m\u001b[31m0.673\u001b[0m  | \u001b[1m\u001b[35m0.864\u001b[0m |   \u001b[1m\u001b[35m0.815\u001b[0m   | \u001b[1m\u001b[36m0.229\u001b[0m | \u001b[1m\u001b[36m0.245\u001b[0m | \u001b[37m1628930940_RNN-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m4\u001b[0m   | \u001b[1m\u001b[37m1.83e-03\u001b[0m | \u001b[1m\u001b[37m1.83e-03\u001b[0m | \u001b[1m\u001b[32m0.776\u001b[0m |  \u001b[1m\u001b[32m0.759\u001b[0m   | \u001b[1m\u001b[31m0.712\u001b[0m | \u001b[1m\u001b[31m0.700\u001b[0m  | \u001b[1m\u001b[35m0.862\u001b[0m |   \u001b[1m\u001b[35m0.812\u001b[0m   | \u001b[1m\u001b[36m0.220\u001b[0m | \u001b[1m\u001b[36m0.240\u001b[0m | \u001b[37m1628930940_RNN-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "model.train(epochs=5, init_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This time the network could achieve some regression. There is a slight overfitting but that is a nice result compared to the Feed-Forward architecture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU(sequences=True)-Flatten-Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now try a more evolved recurrent architecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n",
      "| \u001b[1m\u001b[37mepoch\u001b[0m |  \u001b[1m\u001b[37mlrate\u001b[0m   |  \u001b[1m\u001b[37mlrate\u001b[0m   |       | \u001b[1m\u001b[32maccuracy\u001b[0m |       | \u001b[1m\u001b[31mrecall\u001b[0m |       | \u001b[1m\u001b[35mprecision\u001b[0m |       |  \u001b[1m\u001b[36mMSE\u001b[0m  |                  \u001b[37mExperiment\u001b[0m                  |\n",
      "|       |   \u001b[37mGRU\u001b[0m    |  \u001b[37mDense\u001b[0m   |  \u001b[1m\u001b[32m(0)\u001b[0m  |   \u001b[1m\u001b[32m(1)\u001b[0m    |  \u001b[1m\u001b[31m(0)\u001b[0m  |  \u001b[1m\u001b[31m(1)\u001b[0m   |  \u001b[1m\u001b[35m(0)\u001b[0m  |    \u001b[1m\u001b[35m(1)\u001b[0m    |  \u001b[1m\u001b[36m(0)\u001b[0m  |  \u001b[1m\u001b[36m(1)\u001b[0m  |                                              |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n",
      "|   \u001b[1m\u001b[37m0\u001b[0m   | \u001b[1m\u001b[37m1.00e-01\u001b[0m | \u001b[1m\u001b[37m1.00e-01\u001b[0m | \u001b[1m\u001b[32m0.727\u001b[0m |  \u001b[1m\u001b[32m0.684\u001b[0m   | \u001b[1m\u001b[31m0.924\u001b[0m | \u001b[1m\u001b[31m0.942\u001b[0m  | \u001b[1m\u001b[35m0.690\u001b[0m |   \u001b[1m\u001b[35m0.633\u001b[0m   | \u001b[1m\u001b[36m0.268\u001b[0m | \u001b[1m\u001b[36m0.313\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m1\u001b[0m   | \u001b[1m\u001b[37m6.07e-02\u001b[0m | \u001b[1m\u001b[37m6.07e-02\u001b[0m | \u001b[1m\u001b[32m0.747\u001b[0m |  \u001b[1m\u001b[32m0.693\u001b[0m   | \u001b[1m\u001b[31m0.905\u001b[0m | \u001b[1m\u001b[31m0.910\u001b[0m  | \u001b[1m\u001b[35m0.715\u001b[0m |   \u001b[1m\u001b[35m0.646\u001b[0m   | \u001b[1m\u001b[36m0.250\u001b[0m | \u001b[1m\u001b[36m0.305\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m2\u001b[0m   | \u001b[1m\u001b[37m3.68e-02\u001b[0m | \u001b[1m\u001b[37m3.68e-02\u001b[0m | \u001b[1m\u001b[32m0.755\u001b[0m |  \u001b[1m\u001b[32m0.703\u001b[0m   | \u001b[1m\u001b[31m0.922\u001b[0m | \u001b[1m\u001b[31m0.928\u001b[0m  | \u001b[1m\u001b[35m0.718\u001b[0m |   \u001b[1m\u001b[35m0.651\u001b[0m   | \u001b[1m\u001b[36m0.243\u001b[0m | \u001b[1m\u001b[36m0.295\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m3\u001b[0m   | \u001b[1m\u001b[37m2.23e-02\u001b[0m | \u001b[1m\u001b[37m2.23e-02\u001b[0m | \u001b[1m\u001b[32m0.755\u001b[0m |  \u001b[1m\u001b[32m0.707\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.942\u001b[0m  | \u001b[1m\u001b[35m0.717\u001b[0m |   \u001b[1m\u001b[35m0.652\u001b[0m   | \u001b[1m\u001b[36m0.244\u001b[0m | \u001b[1m\u001b[36m0.292\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m4\u001b[0m   | \u001b[1m\u001b[37m1.35e-02\u001b[0m | \u001b[1m\u001b[37m1.35e-02\u001b[0m | \u001b[1m\u001b[32m0.758\u001b[0m |  \u001b[1m\u001b[32m0.698\u001b[0m   | \u001b[1m\u001b[31m0.922\u001b[0m | \u001b[1m\u001b[31m0.915\u001b[0m  | \u001b[1m\u001b[35m0.722\u001b[0m |   \u001b[1m\u001b[35m0.650\u001b[0m   | \u001b[1m\u001b[36m0.239\u001b[0m | \u001b[1m\u001b[36m0.298\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m5\u001b[0m   | \u001b[1m\u001b[37m8.21e-03\u001b[0m | \u001b[1m\u001b[37m8.21e-03\u001b[0m | \u001b[1m\u001b[32m0.760\u001b[0m |  \u001b[1m\u001b[32m0.707\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.933\u001b[0m  | \u001b[1m\u001b[35m0.721\u001b[0m |   \u001b[1m\u001b[35m0.654\u001b[0m   | \u001b[1m\u001b[36m0.239\u001b[0m | \u001b[1m\u001b[36m0.293\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m6\u001b[0m   | \u001b[1m\u001b[37m4.98e-03\u001b[0m | \u001b[1m\u001b[37m4.98e-03\u001b[0m | \u001b[1m\u001b[32m0.762\u001b[0m |  \u001b[1m\u001b[32m0.703\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.924\u001b[0m  | \u001b[1m\u001b[35m0.724\u001b[0m |   \u001b[1m\u001b[35m0.652\u001b[0m   | \u001b[1m\u001b[36m0.238\u001b[0m | \u001b[1m\u001b[36m0.296\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m7\u001b[0m   | \u001b[1m\u001b[37m3.02e-03\u001b[0m | \u001b[1m\u001b[37m3.02e-03\u001b[0m | \u001b[1m\u001b[32m0.762\u001b[0m |  \u001b[1m\u001b[32m0.698\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.915\u001b[0m  | \u001b[1m\u001b[35m0.724\u001b[0m |   \u001b[1m\u001b[35m0.650\u001b[0m   | \u001b[1m\u001b[36m0.238\u001b[0m | \u001b[1m\u001b[36m0.298\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m8\u001b[0m   | \u001b[1m\u001b[37m1.83e-03\u001b[0m | \u001b[1m\u001b[37m1.83e-03\u001b[0m | \u001b[1m\u001b[32m0.762\u001b[0m |  \u001b[1m\u001b[32m0.698\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.915\u001b[0m  | \u001b[1m\u001b[35m0.724\u001b[0m |   \u001b[1m\u001b[35m0.650\u001b[0m   | \u001b[1m\u001b[36m0.238\u001b[0m | \u001b[1m\u001b[36m0.297\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "|   \u001b[1m\u001b[37m9\u001b[0m   | \u001b[1m\u001b[37m1.11e-03\u001b[0m | \u001b[1m\u001b[37m1.11e-03\u001b[0m | \u001b[1m\u001b[32m0.762\u001b[0m |  \u001b[1m\u001b[32m0.698\u001b[0m   | \u001b[1m\u001b[31m0.926\u001b[0m | \u001b[1m\u001b[31m0.915\u001b[0m  | \u001b[1m\u001b[35m0.724\u001b[0m |   \u001b[1m\u001b[35m0.650\u001b[0m   | \u001b[1m\u001b[36m0.238\u001b[0m | \u001b[1m\u001b[36m0.297\u001b[0m | \u001b[37m1628930985_GRU-2-Seq_Flatten_Dense-2-softmax\u001b[0m |\n",
      "+-------+----------+----------+-------+----------+-------+--------+-------+-----------+-------+-------+----------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "name = 'GRU-2-Seq_Flatten_Dense-2-softmax'\n",
    "\n",
    "se_hPars['learning_rate'] = 0.1\n",
    "se_hPars['softmax_temperature'] = 1\n",
    "\n",
    "gru = GRU(2, sequences=True)\n",
    "\n",
    "flatten = Flatten()\n",
    "\n",
    "dense = Dense(2, softmax)\n",
    "\n",
    "layers = [embedding, gru, flatten, dense]\n",
    "\n",
    "model = EpyNN(layers=layers, name=name)\n",
    "\n",
    "model.initialize(loss='MSE', seed=1, metrics=['accuracy', 'recall', 'precision'], se_hPars=se_hPars.copy(), end='\\r')\n",
    "\n",
    "model.train(epochs=5, init_logs=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
